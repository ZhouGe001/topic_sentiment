{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc0873b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\Anaconda\\envs\\BERTopic_Env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, DatasetDict\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec8875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 若本地有训练好的模型，则可以直接加载\n",
    "model_path = './二分类model'\n",
    "# 加载分词器\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "# 加载模型\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# # 加载预训练的BERT模型和分词器\n",
    "# model_name = 'aspire/acge_text_embedding'\n",
    "# tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a64c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 1200\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载中文情感分析数据集\n",
    "dataset = load_dataset('lansinuote/ChnSentiCorp')\n",
    "dataset['test']\n",
    "\n",
    "# dataset = load_dataset('csv', data_files='../merged.csv')\n",
    "# # 划分数据集，按 8:1:1 比例划分为训练集、验证集和测试集\n",
    "# train_test_split = dataset['train'].train_test_split(test_size=0.2)\n",
    "# test_valid_split = train_test_split['test'].train_test_split(test_size=0.5)\n",
    "# # 创建包含训练集、验证集和测试集的数据集字典\n",
    "# dataset = DatasetDict({\n",
    "#     'train': train_test_split['train'],\n",
    "#     'validation': test_valid_split['train'],\n",
    "#     'test': test_valid_split['test'],\n",
    "# })\n",
    "# dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66aadc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理函数\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ac6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 应用预处理函数到数据集\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "584ebd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义指标计算函数\n",
    "def compute_metrics(pred):\n",
    "    # pred是一个对象，包含预测结果。label_ids是模型的真实标签，表示数据集中每个样本的真实情感类别\n",
    "    labels = pred.label_ids\n",
    "    # predictions是模型的预测结果，是一个包含每个样本预测得分的二维数组。argmax(-1)表示在最后一个维度上取最大值的索引，即取出每个样本的预测类别。\n",
    "    # 简单来说，preds是模型预测的情感类别。\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # average='binary'：指定计算方式。在二分类任务中，使用'binary'表示计算针对正类（通常是标签为1的类）的指标。\n",
    "    # 其他选项包括'micro', 'macro', 'weighted', 以及'samples'，这些用于多分类任务。\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3028ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results-二分类',         # 输出目录\n",
    "    evaluation_strategy='epoch',    # 表示每个epoch结束时进行评估\n",
    "    per_device_train_batch_size=16, # 训练时每个设备上的批次大小\n",
    "    per_device_eval_batch_size=64,  # 评估时每个设备上的批次大小\n",
    "    num_train_epochs=3,             # 训练的轮数\n",
    "    weight_decay=0.01,              # 指定训练过程中的权重衰减为0.01，以防止过拟合\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbae9bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建Trainer对象\n",
    "trainer = Trainer(\n",
    "    model=model,                                    # 模型\n",
    "    args=training_args,                             # 训练参数\n",
    "    train_dataset=encoded_dataset['train'],         # 训练集\n",
    "    eval_dataset=encoded_dataset['validation'],     # 验证集\n",
    "    compute_metrics=compute_metrics,                # 评估指标\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc147b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型，若是使用保存在本地且训练好的模型，则不需要此步骤\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70af8cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:07<00:00,  2.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.27383413910865784,\n",
       " 'eval_accuracy': 0.9366666666666666,\n",
       " 'eval_precision': 0.9480069324090121,\n",
       " 'eval_recall': 0.9224283305227656,\n",
       " 'eval_f1': 0.935042735042735,\n",
       " 'eval_runtime': 8.2136,\n",
       " 'eval_samples_per_second': 146.099,\n",
       " 'eval_steps_per_second': 2.313}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 评估模型\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab28e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model.save_pretrained('./二分类model')\n",
    "tokenizer.save_pretrained('./二分类model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6e5d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推理函数\n",
    "def predict(text):\n",
    "    # 确定设备\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # 将模型移动到相同的设备\n",
    "    model.to(device)\n",
    "    \n",
    "    # 预处理输入文本\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    \n",
    "    # 将输入数据移动到相同的设备\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    # 关闭梯度计算以节省内存和计算力\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # 获取预测结果\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    return \"Positive\" if predictions.item() == 1 else \"Negative\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ccd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 示例推理\n",
    "example_text = \"ChatGPT，我爱你\"\n",
    "print(predict(example_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31550816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 确定设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 关闭模型的训练模式\n",
    "model.eval()\n",
    "\n",
    "# 读取xlsx文件并去重\n",
    "df = pd.read_excel('ChatGPT_去重.xlsx')  # 替换为你的xlsx文件路径\n",
    "def check_length(row):\n",
    "    return len(row['微博博文']) < 200\n",
    "\n",
    "filtered_df = df[df.apply(check_length, axis=1)]\n",
    "\n",
    "# 假设文本内容在\"微博博文\"列\n",
    "texts = filtered_df['微博博文'].tolist()\n",
    "\n",
    "# 定义推理函数\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    return \"Positive\" if predictions.item() == 1 else \"Negative\"\n",
    "\n",
    "# 创建一个进度条\n",
    "tqdm.pandas()\n",
    "\n",
    "# 对每个文本进行情感预测\n",
    "df['sentiment'] = df['微博博文'].progress_apply(predict)\n",
    "\n",
    "# 保存结果回xlsx文件\n",
    "df.to_excel('predicted_sentiments.xlsx', index=False)\n",
    "\n",
    "print(\"情感预测完成，并已保存到predicted_sentiments.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
